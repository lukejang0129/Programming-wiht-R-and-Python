---
title: "Stat_101C_HW3"
author: "Junhyuk Jang"
date: "4/30/2017"
output: pdf_document
---
SID: 004 728 134 DIS: 2A
```{r}
# install.packages("ISLR")
# install.packages("boot",dep = TRUE)
# install.packages("resample")
library("ISLR")
library("ggplot2")
library("boot")
library("resample")
require("boot")
attach(Carseats)
# Q1
# (a)
df <- Carseats
head(df)
summary(df)
dim(df)
summary(df$Sales)
summary(df$CompPrice)
summary(df$Income)
summary(df$Advertising)
summary(df$Population)
summary(df$Price)
summary(df$ShelveLoc)
summary(df$Age)
summary(df$Education)
summary(df$Urban)
summary(df$US)

# (b)
ggplot(df,aes(x = Price,y = Sales)) + geom_smooth() +
        geom_point(shape = 1)
# What did you notice?
# As price increases the sale decreaces monotonically. 

# (c)  & (d)
#Basic confidence interval
my.mean <- function(data,indices){
  d=data[indices]
  mean(d)
}
my.median <- function(data,indices){
  d=data[indices]
  median(d)
}
mean(df$Sales)
(out.bs.mean <- boot(data = df$Sales,statistic = my.mean, R = 1000))
(out.bs.median <- boot(data = df$Sales,statistic = my.median,R = 1000))
(se.mean <- sd(out.bs.mean$t))
(se.median <- sd(out.bs.median$t))
out.bs.mean$t
# CI mean & plot
boot.ci(out.bs.mean)
plot(out.bs.mean) # normally distributed.
# CI median & plot 
boot.ci(out.bs.median)
plot(out.bs.median) # not normally distributed


# Q2
# (A) 
plot(df$Price,df$Sales)
set.seed(77)
train <- sample(400,280)
training_mse<-c()
MSE_training <- function(y,x){
   for(i in 1:9){
    lm.fit<-lm(formula=y~poly(x,i,raw=T),data=df,subset = train)
  training_mse[i]<- mean((y-predict(lm.fit,df))[train]^2)
  }
  return(training_mse)
}
MSE_training(Sales,Price)

# (B) 
set.seed(77)
testing_mse<-c()
MSE_testing <- function(y,x){
   for(i in 1:9){
    lm.fit<-lm(formula=y~poly(x,i,raw=T),data=df,subset = train)
  testing_mse[i]<- mean((y-predict(lm.fit,df))[-train]^2)
  }
  return(testing_mse)
}
MSE_testing(Sales,Price)
(mse_test <- MSE_testing(Sales,Price))

# (C)
plot(1:9,MSE_training(Sales,Price),type = "b",col = "blue",ylab = "MSE",
     main = "Validation Set approach")
points(1:9,mse_test,col = "red",type = "b")
legend("topright", legend=c("Training MSE","Test MSE"),
       col=c("blue", "red"), lty=1:2, cex=0.88,
       box.lty=0)
abline(v = which.min(MSE_testing(Sales,Price)),col = "green")
# INTERPRETATION
# Based on Test MSE, polynomial degree of 1 minimizes the MSE.

# Q3
cv.error1 <- rep(0,9)
for (i in 1:9) {
       glm <- glm(Sales ~ poly(Price,i),data = df)
       cv.error1[i] <- cv.glm(df,glm)$delta[1]
}
cv.error1
# plot & interpretation
plot(1:9,cv.error1,type = "b",col = "blue",ylab = "MSE",
     main = "Leave One Out Cross Validation")
legend("topright", legend="Test MSE",
       col= "blue", lty=1:1, cex=0.88,
       box.lty=1)
abline(v = which.min(cv.error1),col = "green")
# INTERPRETATION
# Based on Test MSE, polynomial degree of 4 minimizes the MSE.

# Q4 
# (a) 
set.seed(77)
# split k = 10
a <- split(sample(1:400),f=rep(1:10,400))
a1 <- a[[1]]
a2 <- a[[2]]
head(df[a1,])
head(df[a2,])

# (b)
set.seed(77)
cv.error.10 <- NULL
for (i in 1:9) {
        glm <- glm(Sales ~ poly(Price,i),data = df)
        cv.error.10[i] <- cv.glm(df,glm,K = 10)$delta[1]
}
cv.error.10

plot(1:9,cv.error.10,type = "b",col = "blue",ylab = "MSE",
     main = "10 - Fold Cross Validation ",ylim = c(5,50))
legend("topright", legend="Test MSE",
       col= "blue", lty=1:1, cex=0.88,
       box.lty=1)
abline(v = which.min(cv.error.10),col = "green")
# INTERPRETATION WHO IS THE BEST? 
# Based on Test MSE, polynomial degree of 4 minimizes the MSE.

# Q5 
plot(1:9,mse_test,type = "b",col = "blue",main = "Three test MSE vs polynomial degree")
points(1:9,cv.error1,col = "red",type = "b")
points(1:9,cv.error.10,col = "green",type = "b")
legend("bottomright", legend=c("Validation Set","LOOCA","10-fold-CV"),
       col=c("blue", "red","Green"), lty=1:2, cex=0.88,
       box.lty=1)s

# INTERPRETATION
# Based on the plot three test Mse vs polynomial degree,
# we can see polynomial degree of 1 and 4 are outperforming than the other
# polynomial degrees.If I have to choose one polynomial degree to fit my model,
# I will choose degree of 4 derived from 10-fold cross validation because 
# leave on out cross validation method is averaging the output of n fitted model 
# ,hence, outputs are highly correlated each. In other words, LOOCV have higher 
# variance than 10-fold CV. In case of the validation set approach, it has two 
# crucial drawbacks. Firstly, error rate can be highly variate depending on
# which observations are included in the training set and which observations are 
# included in the testing set. Secondly, it has higher risk to overestimate testing
# error because we split our data into training and testing which implies that less
# observations are used to make our fitted model.
# For these reassons,I believe making model with polynomial degree of 4 would give us
# the best prediction model.

```
